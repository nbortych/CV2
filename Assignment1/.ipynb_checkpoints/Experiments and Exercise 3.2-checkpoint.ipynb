{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from scipy.io import loadmat\n",
    "import open3d\n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "from open3d import geometry\n",
    "from tqdm import tqdm\n",
    "def affine_transform(pc, R, t):\n",
    "    return np.array([R.dot(a)+t for a in pc])\n",
    "    \n",
    "def background_removal(a_1, normals = []):\n",
    "    \n",
    "    valid_int = (a_1[:,2])<1\n",
    "    a_1 = a_1[valid_int]\n",
    "    if not len(normals) == 0:\n",
    "        normals = normals[valid_int]\n",
    "        return a_1, normals\n",
    "    \n",
    "    return a_1\n",
    "\n",
    "def remove_nan(points, normals):\n",
    "    keep = []\n",
    "    for nan in np.isnan(normals):\n",
    "        if (nan == True).any():\n",
    "            keep.append(False)\n",
    "        else:\n",
    "            keep.append(True)\n",
    "    points = points[keep]\n",
    "    normals = normals[keep]\n",
    "    return (points, normals)\n",
    "\n",
    "def rigid_motion(p,q):\n",
    "    \"\"\"\n",
    "    Least-Squares Rigid Motion Using Singular Value Decomposition. \n",
    "    (https://igl.ethz.ch/projects/ARAP/svd_rot.pdf) \n",
    "    \n",
    "    (note: so far only for the easy case, where all weights are = 1)\n",
    "    \n",
    "    p,q: shape [num_points, 3]\n",
    "    \n",
    "    \"\"\"\n",
    "    n,d = p.shape\n",
    "    \n",
    "    # compute centroids\n",
    "    p_cen = sum(p)/len(p)\n",
    "    q_cen = sum(q)/len(q)\n",
    "    \n",
    "    # compute centered vectors\n",
    "    X = np.array([i-p_cen for i in p])\n",
    "    Y = np.array([i-q_cen for i in q])\n",
    "    \n",
    "    # compute covariance matrix \n",
    "    W = np.eye(n)\n",
    "    S =  X.T.dot(W).dot(Y)\n",
    "    \n",
    "    # compute sigular value decomposition\n",
    "    U, _, V = np.linalg.svd(S)\n",
    "    \n",
    "    # compute optimal R and t\n",
    "    M = np.eye(d)\n",
    "    M[-1,-1] = np.linalg.det(V.T.dot(U.T))\n",
    "    R = V.T.dot(M).dot(U.T)\n",
    "    \n",
    "    t = q_cen - R.dot(p_cen)\n",
    "    \n",
    "    return R, t\n",
    "\n",
    "def rms_error(p, q):\n",
    "    n = p.shape[0]\n",
    "    dist = [distance.euclidean(p[i,:], q[i,:]) for i in range(n)]\n",
    "    return np.sqrt(np.sum(np.power(dist, 2))/n)\n",
    "\n",
    "def show_fitting_result(pcds_list):\n",
    "    \n",
    "    point_clouds_object_list = []\n",
    "    pc = open3d.PointCloud()\n",
    "    for i, pcd in enumerate(pcds_list):\n",
    "        point_clouds_object_list.append(open3d.PointCloud())\n",
    "        point_clouds_object_list[i].points = open3d.Vector3dVector(pcd)\n",
    "    \n",
    "    open3d.draw_geometries(point_clouds_object_list)\n",
    "\n",
    "    \n",
    "def informative_subsampling(normals, sample_size):\n",
    "    # convert normals to angular space\n",
    "    b = np.sqrt(normals[:,0]**2+normals[:,1]**2)\n",
    "    x = np.arctan2(normals[:,1], normals[:,0])\n",
    "    y = np.arctan2(normals[:,2], b)\n",
    "    \n",
    "    # devide normals over bins\n",
    "    bins = np.linspace(-np.pi, np.pi, sample_size) \n",
    "    x_index = np.digitize(x, bins, right=True)\n",
    "    y_index = np.digitize(y, bins, right=True)\n",
    "    index = x_index * sample_size + y_index\n",
    "\n",
    "    # uniformly sample from bins\n",
    "    unique_index, original_index = np.unique(index, return_index=True)\n",
    "    samples = np.random.choice(unique_index.shape[0], sample_size, replace=False)\n",
    "    sample_index = original_index[samples]\n",
    "    \n",
    "    # return only the found sample indices of the original pointcloud\n",
    "    return sample_index    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def icp(a_1, a_2, convergence_treshold=0.0005, point_selection=\"all\", sample_size=1000, generate_3d = True, verbose = True, is_test = False , accuracy_check = False, stability_constant = 1,source_file=None , target_file=None, normals = [], no_background_removal = False):\n",
    "    \"\"\"\n",
    "    a_1: positions of points in point cloud 1. shape : [num_points1, 3]\n",
    "    a_2: positions of points in point cloud 2. shape : [num_points2, 3]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if is_test:\n",
    "        generate_3d = False\n",
    "        verbose = False\n",
    "    n,d = a_1.shape\n",
    "    \n",
    "    if not no_background_removal:\n",
    "    \n",
    "    # Filter the point clouds based on the depth,\n",
    "    # only keep the indices where the z of the point cloud is less than 1\n",
    "        if len(normals) == 0:\n",
    "            a_1, a_2 = background_removal(a_1), background_removal(a_2)\n",
    "        else:\n",
    "            (a_1, normals[0]) = background_removal(a_1, normals[0])\n",
    "            (a_2, normals[1]) = background_removal(a_2, normals[1])\n",
    "    \n",
    "    a_2_c = a_2.copy()\n",
    "    # Point selection\n",
    "    # Uniform subsampling\n",
    "    if point_selection == \"uniform\":\n",
    "        a_1 = a_1[np.random.randint(low=0, high=a_1.shape[0], size=sample_size)]\n",
    "        a_2 = a_2[np.random.randint(low=0, high=a_2.shape[0], size=sample_size)]\n",
    "        \n",
    "    if point_selection == \"informative\":\n",
    "        a_1 = a_1[informative_subsampling(normals[0], sample_size)]\n",
    "        a_2 = a_2[informative_subsampling(normals[1], sample_size)]\n",
    "                 \n",
    "    if stability_constant == 1 :\n",
    "        R_overall = np.eye(d)\n",
    "        t_overall = np.zeros(d)\n",
    "    else:\n",
    "        R_overall = np.random.normal(0,1, size = (d,d))*stability_constant\n",
    "        t_overall = np.random.normal(0,1, size = d)*stability_constant\n",
    "    \n",
    "    # Base loop on difference in rsm error\n",
    "    rms_error_old = 10000\n",
    "    rms_error_new = rms_error_old-1\n",
    "    \n",
    "    while rms_error_old-rms_error_new > convergence_treshold:\n",
    "        \n",
    "        if point_selection == \"random\":\n",
    "            a_1 = a_1[np.random.choice(a_1.shape[0], sample_size, replace=False), :]\n",
    "            a_2 = a_2[np.random.choice(a_2.shape[0], sample_size, replace=False), :]\n",
    "            \n",
    "        # (Step 1) Find closest points for each point in a_1 from a_2\n",
    "        tree = scipy.spatial.KDTree(a_2)\n",
    "        closest_dists, closest_idx = tree.query(a_1)\n",
    "        # Found this on stackoverflow: https://bit.ly/2P8IYiw\n",
    "        # Not sure if we can use this, but it is definetely much (!!) faster \n",
    "        # than manually comparing all the vectors.\n",
    "        # Usage also proposed on Wikipedia: https://bit.ly/2urg9nU\n",
    "        # For how-to-use see: https://bit.ly/2UbKNfn\n",
    "        closest_a_2 = a_2[closest_idx]\n",
    "    \n",
    "        # (Step 2) Refine R and t using Singular Value Decomposition\n",
    "        R, t = rigid_motion(a_1,closest_a_2)\n",
    "       \n",
    "        # update a_1\n",
    "        a_1 =affine_transform(a_1, R, t)\n",
    "        \n",
    "        # update rms error\n",
    "        rms_error_old = rms_error_new\n",
    "        rms_error_new = rms_error(a_1, closest_a_2)\n",
    "        \n",
    "        if verbose:\n",
    "            print(rms_error_new)\n",
    "        \n",
    "        # update overall R and t\n",
    "        R_overall = R.dot(R_overall)\n",
    "        t_overall = R.dot(t_overall) + t\n",
    "    if generate_3d:\n",
    "        show_fitting_result([a_1, a_2_c])\n",
    "    if accuracy_check:\n",
    "        return rms_error_new\n",
    "    return R_overall, t_overall\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Load a ply point cloud, print it, and render it\")\n",
    "# pcd1  = open3d.read_point_cloud(\"Data/data/0000000000.pcd\")\n",
    "# pcd2  = open3d.read_point_cloud(\"Data/data/0000000001.pcd\")\n",
    "# print(np.asarray(pcd.points))\n",
    "# open3d.draw_geometries([pcd])\n",
    "a_1 = loadmat(\"Data/source.mat\")[\"source\"].T\n",
    "a_2 = loadmat(\"Data/target.mat\")[\"target\"].T\n",
    "\n",
    "a_1 = open3d.read_point_cloud(\"Data/data/0000000000.pcd\")\n",
    "a_2 = open3d.read_point_cloud(\"Data/data/0000000010.pcd\")\n",
    "\n",
    "a_1 = np.asarray(a_1.points)\n",
    "a_2 = np.asarray(a_2.points)\n",
    "\n",
    "n_1 = open3d.read_point_cloud(\"Data/data/0000000000_normal.pcd\", format='xyz')\n",
    "n_2 = open3d.read_point_cloud(\"Data/data/0000000010_normal.pcd\", format='xyz')\n",
    "\n",
    "n_1 = np.asarray(n_1.points)\n",
    "n_2 = np.asarray(n_2.points)\n",
    "\n",
    "\n",
    "a_1, n_1  = remove_nan(a_1, n_1)\n",
    "a_2, n_2 = remove_nan(a_2, n_2)\n",
    "\n",
    "\n",
    "#source_file = \"Data/data/0000000000.jpg\"\n",
    "#target_file = \"Data/data/0000000001.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03258754321643644\n",
      "0.022913955786016616\n",
      "0.02115971201033881\n",
      "0.020248994232444494\n",
      "0.019792583746345353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.87997192, -0.03765211, -0.47353115],\n",
       "        [ 0.05502664,  0.9982226 ,  0.02288491],\n",
       "        [ 0.47182783, -0.0461949 ,  0.88047972]]),\n",
       " array([ 0.43097789, -0.02823118,  0.09698219]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icp(a_1, a_2, point_selection = 'informative', normals = [n_1, n_2] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_methods = ['random', 'uniform', \"all\"] \n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time that it takes for random method is:\n",
      "CPU times: user 8.13 s, sys: 203 ms, total: 8.34 s\n",
      "Wall time: 5.12 s\n",
      "Time that it takes for uniform method is:\n",
      "CPU times: user 7.9 s, sys: 169 ms, total: 8.06 s\n",
      "Wall time: 5.59 s\n",
      "Time that it takes for all method is:\n",
      "CPU times: user 47.2 s, sys: 4.01 s, total: 51.3 s\n",
      "Wall time: 43.3 s\n"
     ]
    }
   ],
   "source": [
    "def speed_check(a_1, a_2, sampling_methods):\n",
    "    for method in sampling_methods:\n",
    "        if method == \"informative\":\n",
    "            normals = [n_1, n_2]\n",
    "        else:\n",
    "            normals = []\n",
    "        print(\"Time that it takes for {} method is:\".format(method))\n",
    "        %time  icp(a_1, a_2, point_selection = method, is_test = True , normals=normals)\n",
    "speed_check(a_1, a_2, sampling_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of random method is 0.08269\n",
      "RMSE of uniform method is 0.08705\n",
      "RMSE of all method is 0.02899\n"
     ]
    }
   ],
   "source": [
    "def accuracy_check(a_1, a_2, sampling_methods):\n",
    "    for method in sampling_methods:\n",
    "        if method == \"informative\":\n",
    "            normals = [n_1, n_2]\n",
    "        else:\n",
    "            normals = []\n",
    "        print(\"RMSE of {} method is {:.4}\".format(method, icp(a_1, a_2, point_selection = method, is_test = True, accuracy_check = True, normals = normals)))\n",
    "accuracy_check(a_1, a_2, sampling_methods)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of random method is 0.07941, whereas if we add noise, it becomes 0.3269 , the difference is -0.2475\n",
      "The distance between normal and noisy R matrices is 0.5351 and between normal and noisy t vectors is 0.3728\n",
      "RMSE of uniform method is 0.08523, whereas if we add noise, it becomes 0.3513 , the difference is -0.2661\n",
      "The distance between normal and noisy R matrices is 0.4378 and between normal and noisy t vectors is 0.3449\n",
      "RMSE of all method is 0.02899, whereas if we add noise, it becomes 0.2066 , the difference is -0.1776\n",
      "The distance between normal and noisy R matrices is 0.4928 and between normal and noisy t vectors is 0.5501\n"
     ]
    }
   ],
   "source": [
    "def  noise_check(a_1, a_2, sampling_methods):\n",
    "    noise_1, noise_2 = np.random.normal(0,1,(a_1.shape)) ,np.random.normal(0,1,(a_2.shape))\n",
    "    a_1_noisy, a_2_noisy = a_1 + noise_1 , a_2 + noise_2\n",
    "    \n",
    "    for method in sampling_methods:\n",
    "        if method == \"informative\":\n",
    "            normals = [n_1, n_2]\n",
    "        else:\n",
    "            normals = []\n",
    "        rmse_normal =icp(a_1, a_2, point_selection = method, is_test = True, accuracy_check = True, normals = normals) \n",
    "        \n",
    "        if method == \"informative\":\n",
    "            normals = [n_1, n_2]\n",
    "        else:\n",
    "            normals = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        rmse_noisy = icp(a_1_noisy, a_2_noisy, point_selection = method, is_test = True, accuracy_check = True, normals = normals)\n",
    "        print(\"RMSE of {} method is {:.4}, whereas if we add noise, it becomes {:.4} , the difference is {:.4}\".format(method, rmse_normal, rmse_noisy, rmse_normal - rmse_noisy))\n",
    "       \n",
    "        if method == \"informative\":\n",
    "            normals = [n_1, n_2]\n",
    "        else:\n",
    "            normals = []\n",
    "            \n",
    "            \n",
    "        R_normal , t_normal = icp(a_1, a_2, point_selection = method, is_test = True, normals = normals) \n",
    "        \n",
    "        if method == \"informative\":\n",
    "            normals = [n_1, n_2]\n",
    "        else:\n",
    "            normals = []\n",
    "        \n",
    "        R_noisy , t_noisy = icp(a_1_noisy, a_2_noisy, point_selection = method, is_test = True, normals = normals) \n",
    "        R_distance, t_distance = np.linalg.norm(R_normal - R_noisy), np.linalg.norm(t_normal - t_noisy)\n",
    "        print(\"The distance between normal and noisy R matrices is {:.4} and between normal and noisy t vectors is {:.4}\".format(R_distance, t_distance))\n",
    "        \n",
    "\n",
    "noise_check(a_1, a_2, sampling_methods)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of random method is 0.07902, whereas if we have random initialisation, it becomes 0.08193 , the difference is -0.002905\n",
      "The distance between normal and randomely initialised R matrices is 32.82 and between normal and randomely initialised t vectors is 23.8\n",
      "RMSE of uniform method is 0.08893, whereas if we have random initialisation, it becomes 0.08164 , the difference is 0.007296\n",
      "The distance between normal and randomely initialised R matrices is 32.82 and between normal and randomely initialised t vectors is 20.72\n",
      "RMSE of all method is 0.02899, whereas if we have random initialisation, it becomes 0.02899 , the difference is 0.0\n",
      "The distance between normal and randomely initialised R matrices is 22.01 and between normal and randomely initialised t vectors is 11.28\n"
     ]
    }
   ],
   "source": [
    "def  stability_check(a_1, a_2, sampling_methods):\n",
    "    stability_constant = 10\n",
    "    for method in sampling_methods:\n",
    "        \n",
    "        if method == \"informative\":\n",
    "            normals = [n_1, n_2]\n",
    "        else:\n",
    "            normals = []\n",
    "        rmse_normal =icp(a_1, a_2, point_selection = method, is_test = True, accuracy_check = True, normals = normals) \n",
    "        if method == \"informative\":\n",
    "            normals = [n_1, n_2]\n",
    "        else:\n",
    "            normals = []\n",
    "        \n",
    "        rmse_non_stable= icp(a_1, a_2, point_selection = method, is_test = True, accuracy_check = True, stability_constant = stability_constant, normals = normals)\n",
    "        print(\"RMSE of {} method is {:.4}, whereas if we have random initialisation, it becomes {:.4} , the difference is {:.4}\".format(method, rmse_normal, rmse_non_stable, rmse_normal - rmse_non_stable))\n",
    "        if method == \"informative\":\n",
    "            normals = [n_1, n_2]\n",
    "        else:\n",
    "            normals = []\n",
    "        R_normal , t_normal = icp(a_1, a_2, point_selection = method, is_test = True, normals = normals) \n",
    "        if method == \"informative\":\n",
    "            normals = [n_1, n_2]\n",
    "        else:\n",
    "            normals = []\n",
    "        R_non_stable , t_non_stable = icp(a_1, a_2, point_selection = method, is_test = True, stability_constant = stability_constant, normals = normals) \n",
    "        R_distance, t_distance = np.linalg.norm(R_normal - R_non_stable), np.linalg.norm(t_normal - t_non_stable)\n",
    "        print(\"The distance between normal and randomely initialised R matrices is {:.4} and between normal and randomely initialised t vectors is {:.4}\".format(R_distance, t_distance))\n",
    "        \n",
    "\n",
    "stability_check(a_1, a_2, sampling_methods)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data preparation cell\n",
    "def read_pcds_from_filenames(filenames, is_normal = False):\n",
    "    \"\"\"\n",
    "    Read point clouds for given file names.\n",
    "    \"\"\"\n",
    "    if not is_normal:\n",
    "        return [open3d.read_point_cloud(f)for f in filenames]\n",
    "    else: \n",
    "        return [open3d.read_point_cloud(f, format = \"xyz\")for f in filenames]\n",
    "#data preparation\n",
    "\n",
    "def prepare_data(frame_interval=1, data_dir=\"./Data/data/\", max_images = 99):\n",
    "    filenames = []#data_dir+x for x in os.listdir(data_dir) if re.match(r\"00000000[0-9][0-9].pcd\",x)]\n",
    "    normals_filenames = []#data_dir+x for x in #s.listdir(data_dir) if re.match(r\"00000000[0-9][0-9]_normal.pcd\",x)]\n",
    "    for i in range(max_images+1):\n",
    "        if i<10:\n",
    "            filenames.append(\"{}000000000{}.pcd\".format(data_dir, i))\n",
    "            normals_filenames.append(\"{}000000000{}_normal.pcd\".format(data_dir, i))\n",
    "        else:\n",
    "            filenames.append(\"{}00000000{}.pcd\".format(data_dir, i))\n",
    "            normals_filenames.append(\"{}00000000{}_normal.pcd\".format(data_dir, i))\n",
    "    \n",
    "\n",
    "    normals_filenames.sort()\n",
    "    filenames.sort()\n",
    "    \n",
    "    # Get relevant filenames (according to frame_interval)\n",
    "    filenames=filenames[0::frame_interval]\n",
    "    normals_filenames = normals_filenames[0::frame_interval]\n",
    "    \n",
    "    # Get point clouds for relevant filnames\n",
    "    pcds = read_pcds_from_filenames(filenames)\n",
    "    normals = read_pcds_from_filenames(normals_filenames, True)\n",
    "    normals = [np.array(n.points) for n in normals]\n",
    "\n",
    "    #remove background and nan normals\n",
    "    pcd_points = [background_removal(remove_nan(np.array(p.points), n)[0]) for p, n in zip(pcds, normals)]\n",
    "    \n",
    "    return pcd_points\n",
    "\n",
    "\n",
    "\n",
    "pcd_points = prepare_data(frame_interval=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/98 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 1/98 [00:00<00:40,  2.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 2/98 [00:01<00:53,  1.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 3/98 [00:01<00:50,  1.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 4/98 [00:02<00:50,  1.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 5/98 [00:02<00:54,  1.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 6/98 [00:03<00:55,  1.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 7/98 [00:04<00:56,  1.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 8/98 [00:05<00:57,  1.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  9%|▉         | 9/98 [00:06<01:02,  1.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-5af8319c4546>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mshow_fitting_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmerging_scenes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-5af8319c4546>\u001b[0m in \u001b[0;36mmerging_scenes\u001b[0;34m(frame_interval, point_selection, data_dir, max_images)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#transform total to the new frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maffine_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m#add a subsample of the next frame to total\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_next_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_next_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-5af8319c4546>\u001b[0m in \u001b[0;36maffine_transform\u001b[0;34m(pc, R, t)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Exercise 3.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maffine_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpc\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmerging_scenes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_selection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./Data/data/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_images\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#Exercise 3.2\n",
    "def affine_transform(pc, R, t):\n",
    "    return np.array([R.dot(x)+t for x in pc ])\n",
    "\n",
    "def merging_scenes(frame_interval=1, point_selection='uniform', data_dir=\"./Data/data/\", max_images =99):  \n",
    "    # start with initial variable for commulative\n",
    "    total =  pcd_points[0][np.random.randint(low=0, high=pcd_points[0].shape[0], size=1010)]\n",
    "    for i in tqdm(range(1, len(pcd_points)-1)):\n",
    "        \n",
    "        #sample next frame\n",
    "        sample_next_frame = pcd_points[i]\n",
    "        #estimate R and t from total to the next frame\n",
    "        R,t = icp( total, sample_next_frame, is_test=True, point_selection=point_selection, no_background_removal = True)\n",
    "        \n",
    "        #transform total to the new frame\n",
    "        total = affine_transform(total, R, t)\n",
    "        #add a subsample of the next frame to total\n",
    "        total = np.concatenate((total, sample_next_frame[np.random.randint(low=0, high=sample_next_frame.shape[0], size=14000),:]))\n",
    "    \n",
    "        #plot 3d every 20 frames\n",
    "        if i%20==0:\n",
    "            show_fitting_result([total])\n",
    "    show_fitting_result([total])\n",
    "    \n",
    "merging_scenes()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
