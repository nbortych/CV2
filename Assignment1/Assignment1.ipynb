{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from scipy.io import loadmat\n",
    "import open3d\n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "from open3d import geometry\n",
    "from tqdm import tqdm\n",
    "def affine_transform(pc, R, t):\n",
    "    return np.array([R.dot(a)+t for a in pc])\n",
    "    \n",
    "def background_removal(a_1, normals = []):\n",
    "    \n",
    "    valid_int = (a_1[:,2])<1\n",
    "    a_1 = a_1[valid_int]\n",
    "    if not len(normals) == 0:\n",
    "        normals = normals[valid_int]\n",
    "        return a_1, normals\n",
    "    \n",
    "    return a_1\n",
    "\n",
    "def remove_nan(points, normals):\n",
    "    keep = []\n",
    "    for nan in np.isnan(normals):\n",
    "        if (nan == True).any():\n",
    "            keep.append(False)\n",
    "        else:\n",
    "            keep.append(True)\n",
    "    points = points[keep]\n",
    "    normals = normals[keep]\n",
    "    return (points, normals)\n",
    "\n",
    "def rigid_motion(p,q):\n",
    "    \"\"\"\n",
    "    Least-Squares Rigid Motion Using Singular Value Decomposition. \n",
    "    (https://igl.ethz.ch/projects/ARAP/svd_rot.pdf) \n",
    "    \n",
    "    (note: so far only for the easy case, where all weights are = 1)\n",
    "    \n",
    "    p,q: shape [num_points, 3]\n",
    "    \n",
    "    \"\"\"\n",
    "    n,d = p.shape\n",
    "    \n",
    "    # compute centroids\n",
    "    p_cen = sum(p)/len(p)\n",
    "    q_cen = sum(q)/len(q)\n",
    "    \n",
    "    # compute centered vectors\n",
    "    X = np.array([i-p_cen for i in p])\n",
    "    Y = np.array([i-q_cen for i in q])\n",
    "    \n",
    "    # compute covariance matrix \n",
    "    W = np.eye(n)\n",
    "    S =  X.T.dot(W).dot(Y)\n",
    "    \n",
    "    # compute sigular value decomposition\n",
    "    U, _, V = np.linalg.svd(S)\n",
    "    \n",
    "    # compute optimal R and t\n",
    "    M = np.eye(d)\n",
    "    M[-1,-1] = np.linalg.det(V.T.dot(U.T))\n",
    "    R = V.T.dot(M).dot(U.T)\n",
    "    \n",
    "    t = q_cen - R.dot(p_cen)\n",
    "    \n",
    "    return R, t\n",
    "\n",
    "def rms_error(p, q):\n",
    "    n = p.shape[0]\n",
    "    dist = [distance.euclidean(p[i,:], q[i,:]) for i in range(n)]\n",
    "    return np.sqrt(np.sum(np.power(dist, 2))/n)\n",
    "\n",
    "def show_fitting_result(pcds_list):\n",
    "    \n",
    "    point_clouds_object_list = []\n",
    "    pc = open3d.PointCloud()\n",
    "    for i, pcd in enumerate(pcds_list):\n",
    "        point_clouds_object_list.append(open3d.PointCloud())\n",
    "        point_clouds_object_list[i].points = open3d.Vector3dVector(pcd)\n",
    "    \n",
    "    open3d.draw_geometries(point_clouds_object_list)\n",
    "\n",
    "    \n",
    "def informative_subsampling(normals, sample_size):\n",
    "    # convert normals to angular space\n",
    "    b = np.sqrt(normals[:,0]**2+normals[:,1]**2)\n",
    "    x = np.arctan2(normals[:,1], normals[:,0])\n",
    "    y = np.arctan2(normals[:,2], b)\n",
    "    \n",
    "    # devide normals over bins\n",
    "    bins = np.linspace(-np.pi, np.pi, sample_size) \n",
    "    x_index = np.digitize(x, bins, right=True)\n",
    "    y_index = np.digitize(y, bins, right=True)\n",
    "    index = x_index * sample_size + y_index\n",
    "\n",
    "    # uniformly sample from bins\n",
    "    unique_index, original_index = np.unique(index, return_index=True)\n",
    "    samples = np.random.choice(unique_index.shape[0], sample_size, replace=False)\n",
    "    sample_index = original_index[samples]\n",
    "    \n",
    "    # return only the found sample indices of the original pointcloud\n",
    "    return sample_index    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def icp(a_1, a_2, convergence_treshold=0.0005, point_selection=\"all\", sample_size=1000, generate_3d = True, verbose = True, is_test = False , accuracy_check = False, stability_constant = 1,source_file=None , target_file=None, normals = [], no_background_removal = False):\n",
    "    \"\"\"\n",
    "    a_1: positions of points in point cloud 1. shape : [num_points1, 3]\n",
    "    a_2: positions of points in point cloud 2. shape : [num_points2, 3]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if is_test:\n",
    "        generate_3d = False\n",
    "        verbose = False\n",
    "    n,d = a_1.shape\n",
    "    \n",
    "    if not no_background_removal:\n",
    "    \n",
    "    # Filter the point clouds based on the depth,\n",
    "    # only keep the indices where the z of the point cloud is less than 1\n",
    "        if len(normals) == 0:\n",
    "            a_1, a_2 = background_removal(a_1), background_removal(a_2)\n",
    "        else:\n",
    "            (a_1, normals[0]) = background_removal(a_1, normals[0])\n",
    "            (a_2, normals[1]) = background_removal(a_2, normals[1])\n",
    "    \n",
    "    a_2_c = a_2.copy()\n",
    "    # Point selection\n",
    "    # Uniform subsampling\n",
    "    if point_selection == \"uniform\":\n",
    "        a_1 = a_1[np.random.randint(low=0, high=a_1.shape[0], size=sample_size)]\n",
    "        a_2 = a_2[np.random.randint(low=0, high=a_2.shape[0], size=sample_size)]\n",
    "        \n",
    "    if point_selection == \"informative\":\n",
    "        a_1 = a_1[informative_subsampling(normals[0], sample_size)]\n",
    "        a_2 = a_2[informative_subsampling(normals[1], sample_size)]\n",
    "                 \n",
    "    if stability_constant == 1 :\n",
    "        R_overall = np.eye(d)\n",
    "        t_overall = np.zeros(d)\n",
    "    else:\n",
    "        R_overall = np.random.normal(0,1, size = (d,d))*stability_constant\n",
    "        t_overall = np.random.normal(0,1, size = d)*stability_constant\n",
    "    \n",
    "    # Base loop on difference in rsm error\n",
    "    rms_error_old = 10000\n",
    "    rms_error_new = rms_error_old-1\n",
    "    \n",
    "    while rms_error_old-rms_error_new > convergence_treshold:\n",
    "        \n",
    "        if point_selection == \"random\":\n",
    "            a_1 = a_1[np.random.choice(a_1.shape[0], sample_size, replace=False), :]\n",
    "            a_2 = a_2[np.random.choice(a_2.shape[0], sample_size, replace=False), :]\n",
    "            \n",
    "        # (Step 1) Find closest points for each point in a_1 from a_2\n",
    "        tree = scipy.spatial.KDTree(a_2)\n",
    "        closest_dists, closest_idx = tree.query(a_1)\n",
    "        # Found this on stackoverflow: https://bit.ly/2P8IYiw\n",
    "        # Not sure if we can use this, but it is definetely much (!!) faster \n",
    "        # than manually comparing all the vectors.\n",
    "        # Usage also proposed on Wikipedia: https://bit.ly/2urg9nU\n",
    "        # For how-to-use see: https://bit.ly/2UbKNfn\n",
    "        closest_a_2 = a_2[closest_idx]\n",
    "    \n",
    "        # (Step 2) Refine R and t using Singular Value Decomposition\n",
    "        R, t = rigid_motion(a_1,closest_a_2)\n",
    "       \n",
    "        # update a_1\n",
    "        a_1 =affine_transform(a_1, R, t)\n",
    "        \n",
    "        # update rms error\n",
    "        rms_error_old = rms_error_new\n",
    "        rms_error_new = rms_error(a_1, closest_a_2)\n",
    "        \n",
    "        if verbose:\n",
    "            print(rms_error_new)\n",
    "        \n",
    "        # update overall R and t\n",
    "        R_overall = R.dot(R_overall)\n",
    "        t_overall = R.dot(t_overall) + t\n",
    "    if generate_3d:\n",
    "        show_fitting_result([a_1, a_2_c])\n",
    "    if accuracy_check:\n",
    "        return rms_error_new\n",
    "    return R_overall, t_overall\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Load a ply point cloud, print it, and render it\")\n",
    "# pcd1  = open3d.read_point_cloud(\"Data/data/0000000000.pcd\")\n",
    "# pcd2  = open3d.read_point_cloud(\"Data/data/0000000001.pcd\")\n",
    "# print(np.asarray(pcd.points))\n",
    "# open3d.draw_geometries([pcd])\n",
    "a_1 = loadmat(\"Data/source.mat\")[\"source\"].T\n",
    "a_2 = loadmat(\"Data/target.mat\")[\"target\"].T\n",
    "\n",
    "a_1 = open3d.read_point_cloud(\"Data/data/0000000000.pcd\")\n",
    "a_2 = open3d.read_point_cloud(\"Data/data/0000000010.pcd\")\n",
    "\n",
    "a_1 = np.asarray(a_1.points)\n",
    "a_2 = np.asarray(a_2.points)\n",
    "\n",
    "n_1 = open3d.read_point_cloud(\"Data/data/0000000000_normal.pcd\", format='xyz')\n",
    "n_2 = open3d.read_point_cloud(\"Data/data/0000000010_normal.pcd\", format='xyz')\n",
    "\n",
    "n_1 = np.asarray(n_1.points)\n",
    "n_2 = np.asarray(n_2.points)\n",
    "\n",
    "\n",
    "a_1, n_1  = remove_nan(a_1, n_1)\n",
    "a_2, n_2 = remove_nan(a_2, n_2)\n",
    "\n",
    "\n",
    "#source_file = \"Data/data/0000000000.jpg\"\n",
    "#target_file = \"Data/data/0000000001.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03258754321643644\n",
      "0.022913955786016616\n",
      "0.02115971201033881\n",
      "0.020248994232444494\n",
      "0.019792583746345353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.87997192, -0.03765211, -0.47353115],\n",
       "        [ 0.05502664,  0.9982226 ,  0.02288491],\n",
       "        [ 0.47182783, -0.0461949 ,  0.88047972]]),\n",
       " array([ 0.43097789, -0.02823118,  0.09698219]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icp(a_1, a_2, point_selection = 'informative', normals = [n_1, n_2] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_methods = ['random', 'uniform', \"all\"] \n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time that it takes for random method is:\n",
      "CPU times: user 8.13 s, sys: 203 ms, total: 8.34 s\n",
      "Wall time: 5.12 s\n",
      "Time that it takes for uniform method is:\n",
      "CPU times: user 7.9 s, sys: 169 ms, total: 8.06 s\n",
      "Wall time: 5.59 s\n",
      "Time that it takes for all method is:\n",
      "CPU times: user 47.2 s, sys: 4.01 s, total: 51.3 s\n",
      "Wall time: 43.3 s\n"
     ]
    }
   ],
   "source": [
    "def speed_check(a_1, a_2, sampling_methods):\n",
    "    for method in sampling_methods:\n",
    "        if method == \"informative\":\n",
    "            normals = [n_1, n_2]\n",
    "        else:\n",
    "            normals = []\n",
    "        print(\"Time that it takes for {} method is:\".format(method))\n",
    "        %time  icp(a_1, a_2, point_selection = method, is_test = True , normals=normals)\n",
    "speed_check(a_1, a_2, sampling_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of random method is 0.08269\n",
      "RMSE of uniform method is 0.08705\n",
      "RMSE of all method is 0.02899\n"
     ]
    }
   ],
   "source": [
    "def accuracy_check(a_1, a_2, sampling_methods):\n",
    "    for method in sampling_methods:\n",
    "        if method == \"informative\":\n",
    "            normals = [n_1, n_2]\n",
    "        else:\n",
    "            normals = []\n",
    "        print(\"RMSE of {} method is {:.4}\".format(method, icp(a_1, a_2, point_selection = method, is_test = True, accuracy_check = True, normals = normals)))\n",
    "accuracy_check(a_1, a_2, sampling_methods)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of random method is 0.07941, whereas if we add noise, it becomes 0.3269 , the difference is -0.2475\n",
      "The distance between normal and noisy R matrices is 0.5351 and between normal and noisy t vectors is 0.3728\n",
      "RMSE of uniform method is 0.08523, whereas if we add noise, it becomes 0.3513 , the difference is -0.2661\n",
      "The distance between normal and noisy R matrices is 0.4378 and between normal and noisy t vectors is 0.3449\n",
      "RMSE of all method is 0.02899, whereas if we add noise, it becomes 0.2066 , the difference is -0.1776\n",
      "The distance between normal and noisy R matrices is 0.4928 and between normal and noisy t vectors is 0.5501\n"
     ]
    }
   ],
   "source": [
    "def  noise_check(a_1, a_2, sampling_methods):\n",
    "    noise_1, noise_2 = np.random.normal(0,1,(a_1.shape)) ,np.random.normal(0,1,(a_2.shape))\n",
    "    a_1_noisy, a_2_noisy = a_1 + noise_1 , a_2 + noise_2\n",
    "    \n",
    "    for method in sampling_methods:\n",
    "        if method == \"informative\":\n",
    "            normals = [n_1, n_2]\n",
    "        else:\n",
    "            normals = []\n",
    "        rmse_normal =icp(a_1, a_2, point_selection = method, is_test = True, accuracy_check = True, normals = normals) \n",
    "        \n",
    "        if method == \"informative\":\n",
    "            normals = [n_1, n_2]\n",
    "        else:\n",
    "            normals = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        rmse_noisy = icp(a_1_noisy, a_2_noisy, point_selection = method, is_test = True, accuracy_check = True, normals = normals)\n",
    "        print(\"RMSE of {} method is {:.4}, whereas if we add noise, it becomes {:.4} , the difference is {:.4}\".format(method, rmse_normal, rmse_noisy, rmse_normal - rmse_noisy))\n",
    "       \n",
    "        if method == \"informative\":\n",
    "            normals = [n_1, n_2]\n",
    "        else:\n",
    "            normals = []\n",
    "            \n",
    "            \n",
    "        R_normal , t_normal = icp(a_1, a_2, point_selection = method, is_test = True, normals = normals) \n",
    "        \n",
    "        if method == \"informative\":\n",
    "            normals = [n_1, n_2]\n",
    "        else:\n",
    "            normals = []\n",
    "        \n",
    "        R_noisy , t_noisy = icp(a_1_noisy, a_2_noisy, point_selection = method, is_test = True, normals = normals) \n",
    "        R_distance, t_distance = np.linalg.norm(R_normal - R_noisy), np.linalg.norm(t_normal - t_noisy)\n",
    "        print(\"The distance between normal and noisy R matrices is {:.4} and between normal and noisy t vectors is {:.4}\".format(R_distance, t_distance))\n",
    "        \n",
    "\n",
    "noise_check(a_1, a_2, sampling_methods)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of random method is 0.07902, whereas if we have random initialisation, it becomes 0.08193 , the difference is -0.002905\n",
      "The distance between normal and randomely initialised R matrices is 32.82 and between normal and randomely initialised t vectors is 23.8\n",
      "RMSE of uniform method is 0.08893, whereas if we have random initialisation, it becomes 0.08164 , the difference is 0.007296\n",
      "The distance between normal and randomely initialised R matrices is 32.82 and between normal and randomely initialised t vectors is 20.72\n",
      "RMSE of all method is 0.02899, whereas if we have random initialisation, it becomes 0.02899 , the difference is 0.0\n",
      "The distance between normal and randomely initialised R matrices is 22.01 and between normal and randomely initialised t vectors is 11.28\n"
     ]
    }
   ],
   "source": [
    "def  stability_check(a_1, a_2, sampling_methods):\n",
    "    stability_constant = 10\n",
    "    for method in sampling_methods:\n",
    "        \n",
    "        if method == \"informative\":\n",
    "            normals = [n_1, n_2]\n",
    "        else:\n",
    "            normals = []\n",
    "        rmse_normal =icp(a_1, a_2, point_selection = method, is_test = True, accuracy_check = True, normals = normals) \n",
    "        if method == \"informative\":\n",
    "            normals = [n_1, n_2]\n",
    "        else:\n",
    "            normals = []\n",
    "        \n",
    "        rmse_non_stable= icp(a_1, a_2, point_selection = method, is_test = True, accuracy_check = True, stability_constant = stability_constant, normals = normals)\n",
    "        print(\"RMSE of {} method is {:.4}, whereas if we have random initialisation, it becomes {:.4} , the difference is {:.4}\".format(method, rmse_normal, rmse_non_stable, rmse_normal - rmse_non_stable))\n",
    "        if method == \"informative\":\n",
    "            normals = [n_1, n_2]\n",
    "        else:\n",
    "            normals = []\n",
    "        R_normal , t_normal = icp(a_1, a_2, point_selection = method, is_test = True, normals = normals) \n",
    "        if method == \"informative\":\n",
    "            normals = [n_1, n_2]\n",
    "        else:\n",
    "            normals = []\n",
    "        R_non_stable , t_non_stable = icp(a_1, a_2, point_selection = method, is_test = True, stability_constant = stability_constant, normals = normals) \n",
    "        R_distance, t_distance = np.linalg.norm(R_normal - R_non_stable), np.linalg.norm(t_normal - t_non_stable)\n",
    "        print(\"The distance between normal and randomely initialised R matrices is {:.4} and between normal and randomely initialised t vectors is {:.4}\".format(R_distance, t_distance))\n",
    "        \n",
    "\n",
    "stability_check(a_1, a_2, sampling_methods)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Take stability as an example, an experimental setup may be the following: given a source point cloud, augmented target point cloud can be obtained by transforming the source point cloud using a random rigid transform R and t. Stability can be analyzed by observing a behaviour of ICP on source and augmented target point cloud w.r.t changes in magnitude of R and t.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- stability is about convergence of the algorithm dependent on initial condition.\n",
    "\n",
    "- tolerance to noise is about convergence of the algorithm with input data with noise. You can imagine data is captured by a sensor. In the ideal case you will obtain exact point cloud, however sensor is not precise, therefore there will be noise in measurement. Therefore we ask you to evaluate how ICP is robust against those kind of issuses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data preparation cell\n",
    "def read_pcds_from_filenames(filenames, is_normal = False):\n",
    "    \"\"\"\n",
    "    Read point clouds for given file names.\n",
    "    \"\"\"\n",
    "    if not is_normal:\n",
    "        return [open3d.read_point_cloud(f)for f in filenames]\n",
    "    else: \n",
    "        return [open3d.read_point_cloud(f, format = \"xyz\")for f in filenames]\n",
    "\n",
    "def affine_transform(pc, R, t):\n",
    "    return np.array([R.dot(a)+t for a in pc])\n",
    "    \n",
    "def background_removal(a_1):\n",
    "    valid_bool_1 = (a_1[:,2])<1\n",
    "    a_1 = a_1[valid_bool_1]\n",
    "    return a_1\n",
    "\n",
    "def prepare_data(frame_interval=1, data_dir=\"./Data/data/\", max_images = 99):\n",
    "    filenames = []#data_dir+x for x in os.listdir(data_dir) if re.match(r\"00000000[0-9][0-9].pcd\",x)]\n",
    "    normals_filenames = []#data_dir+x for x in #s.listdir(data_dir) if re.match(r\"00000000[0-9][0-9]_normal.pcd\",x)]\n",
    "    for i in range(max_images+1):\n",
    "        if i<10:\n",
    "            filenames.append(\"{}000000000{}.pcd\".format(data_dir, i))\n",
    "            normals_filenames.append(\"{}000000000{}_normal.pcd\".format(data_dir, i))\n",
    "        else:\n",
    "            filenames.append(\"{}00000000{}.pcd\".format(data_dir, i))\n",
    "            normals_filenames.append(\"{}00000000{}_normal.pcd\".format(data_dir, i))\n",
    "    \n",
    "\n",
    "    normals_filenames.sort()\n",
    "    filenames.sort()\n",
    "    \n",
    "    # Get relevant filenames (according to frame_interval)\n",
    "    filenames=filenames[0::frame_interval]\n",
    "    normals_filenames = normals_filenames[0::frame_interval]\n",
    "    \n",
    "    # Get point clouds for relevant filnames\n",
    "    pcds = read_pcds_from_filenames(filenames)\n",
    "    normals = read_pcds_from_filenames(normals_filenames, True)\n",
    "    normals = [np.array(n.points) for n in normals]\n",
    "\n",
    "    \n",
    "    pcd_points = [background_removal(remove_nan(np.array(p.points), n)[0]) for p, n in zip(pcds, normals)]\n",
    "    \n",
    "    return pcd_points\n",
    "\n",
    "\n",
    "\n",
    "pcd_points = prepare_data(frame_interval=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/99 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (3,3) and (100,3) not aligned: 3 (dim 1) != 100 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c1711d068eeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mmerging_scenes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-c1711d068eeb>\u001b[0m in \u001b[0;36mmerging_scenes\u001b[0;34m(pcd_points, point_selection)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Perform ICP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0micp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcd_points\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpcd_points\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_selection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoint_selection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Update transformations back to zero frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-15f8245ba4df>\u001b[0m in \u001b[0;36micp\u001b[0;34m(a_1, a_2, convergence_treshold, point_selection, sample_size, generate_3d, verbose, is_test, accuracy_check, stability_constant, source_file, target_file, normals, no_background_removal)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# update a_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0ma_1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0maffine_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;31m# update rms error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-6dd735ccfe1f>\u001b[0m in \u001b[0;36maffine_transform\u001b[0;34m(pc, R, t)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#3.1 approach 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maffine_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmerging_scenes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcd_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_selection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uniform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (3,3) and (100,3) not aligned: 3 (dim 1) != 100 (dim 0)"
     ]
    }
   ],
   "source": [
    "#3.1 approach 1\n",
    "\n",
    "def merging_scenes(pcd_points= pcd_points, point_selection='uniform'):\n",
    "    \n",
    "  \n",
    "    \n",
    "    # Tansform all frames back to zero-frame space \n",
    "    R_to_zero_current = np.eye(3)\n",
    "    t_to_zero_current = np.zeros(3)\n",
    "    transformed_points = []\n",
    "    \n",
    "    for i in tqdm(range(1, len(pcd_points))):\n",
    "        \n",
    "        # Perform ICP\n",
    "        R,t = icp(pcd_points[i], pcd_points[i-1], is_test=True, point_selection=point_selection)\n",
    "        \n",
    "        # Update transformations back to zero frame\n",
    "        R_to_zero_current = R.dot(R_to_zero_current)\n",
    "        t_to_zero_current = R.dot(t_to_zero_current) + t\n",
    "        \n",
    "        # Project current PointCloud back to 0-frame space\n",
    "        \n",
    "        transformed_points += [affine_transform(pcd_points[i][np.random.randint(low=0, high=pcd_points[i].shape[0], size=600)] , R_to_zero_current , t_to_zero_current)]\n",
    "    \n",
    "    # Remove backgrounds in our pcds\n",
    "    # pcd_points = [background_removal(p) for p in pcd_points]\n",
    "    \n",
    "    \n",
    "    # Apply transformation to pcd\n",
    "    # pcd_points_transformed = [affine_transform(pcd_points[i],R_list[i], t_list[i]) \n",
    "                              #for i in range(len(pcd_points)-1)]\n",
    "    \n",
    "    #for i in range(len(pcds)):\n",
    "    #    pcds[i].points = pcd_points_transformed[i]\n",
    "        \n",
    "    show_fitting_result(transformed_points)\n",
    "    \n",
    "    \n",
    "merging_scenes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/99 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 1/99 [00:02<03:33,  2.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-1b79bd7675f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mmerging_scenes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcd_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-1b79bd7675f3>\u001b[0m in \u001b[0;36mmerging_scenes\u001b[0;34m(pcd_points, point_selection)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Project current PointCloud back to 0-frame space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maffine_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpcd_points\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpcd_points\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-1b79bd7675f3>\u001b[0m in \u001b[0;36maffine_transform\u001b[0;34m(pc, R, t)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#3.1 approach 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maffine_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mt\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmerging_scenes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcd_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_selection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uniform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#3.1 approach 2\n",
    "def affine_transform(pc, R, t):\n",
    "    return np.array([R.dot(x)+t  for x in pc])\n",
    "\n",
    "def merging_scenes(pcd_points, point_selection='uniform'):\n",
    "\n",
    "\n",
    "    \n",
    "    # Tansform all frames back to zero-frame space \n",
    "    R_to_zero_current = np.eye(3)\n",
    "    t_to_zero_current = np.zeros(3)\n",
    "    \n",
    "    \n",
    "\n",
    "    total =  pcd_points[0]#[np.random.randint(low=0, high=pcd_points[0].shape[0], size=1000)]\n",
    "    for i in tqdm(range(0, len(pcd_points)-1)):\n",
    "        \n",
    "        # Perform ICP\n",
    "        R, t = icp(pcd_points[i], pcd_points[i+1], is_test=True, point_selection=point_selection)\n",
    "        \n",
    "        # Update transformations back to zero frame\n",
    "        #R_to_zero_current = R.dot(R_to_zero_current)\n",
    "        #t_to_zero_current = R.dot(t_to_zero_current) + t\n",
    "        \n",
    "        # Project current PointCloud back to 0-frame space\n",
    "        total = affine_transform(total, R, t)\n",
    "        total = np.concatenate((total,pcd_points[i+1][np.random.randint(low=0, high=pcd_points[i+1].shape[0], size=600)] )) \n",
    "    \n",
    "    # Remove backgrounds in our pcds\n",
    "    # pcd_points = [background_removal(p) for p in pcd_points]\n",
    "    \n",
    "    \n",
    "    # Apply transformation to pcd\n",
    "    # pcd_points_transformed = [affine_transform(pcd_points[i],R_list[i], t_list[i]) \n",
    "                              #for i in range(len(pcd_points)-1)]\n",
    "    \n",
    "    #for i in range(len(pcds)):\n",
    "    #    pcds[i].points = pcd_points_transformed[i]\n",
    "        \n",
    "    show_fitting_result(total)\n",
    "    \n",
    "    \n",
    "merging_scenes(pcd_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/98 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 1/98 [00:00<00:24,  4.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 2/98 [00:00<00:28,  3.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 3/98 [00:01<00:37,  2.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|▍         | 4/98 [00:02<00:50,  1.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|▌         | 5/98 [00:03<00:58,  1.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|▌         | 6/98 [00:04<01:08,  1.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  7%|▋         | 7/98 [00:05<01:15,  1.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|▊         | 8/98 [00:08<01:37,  1.08s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  9%|▉         | 9/98 [00:11<01:52,  1.26s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|█         | 10/98 [00:14<02:03,  1.40s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 11%|█         | 11/98 [00:16<02:10,  1.50s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 12%|█▏        | 12/98 [00:19<02:19,  1.62s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 13%|█▎        | 13/98 [00:22<02:25,  1.71s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-614bb8bd469a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mshow_fitting_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransformed_points\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mmerging_scenes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-614bb8bd469a>\u001b[0m in \u001b[0;36mmerging_scenes\u001b[0;34m(frame_interval, point_selection, data_dir, max_images)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Project current PointCloud back to 0-frame space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mtransformed_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maffine_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-162f1a0b1ca9>\u001b[0m in \u001b[0;36maffine_transform\u001b[0;34m(pc, R, t)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maffine_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbackground_removal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-162f1a0b1ca9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maffine_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbackground_removal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#3.2\n",
    "def affine_transform_new(pc, R, t):\n",
    "    return [R.dot(x)+t for x in pc ]\n",
    "\n",
    "def merging_scenes(frame_interval=1, point_selection='uniform', data_dir=\"./Data/data/\", max_images =99):\n",
    "    \n",
    "    # Tansform all frames back to zero-frame space \n",
    "    R_to_zero_current = np.eye(3)\n",
    "    t_to_zero_current = np.zeros(3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    transformed_points =  pcd_points[0][np.random.randint(low=0, high=pcd_points[0].shape[0], size=1010)]\n",
    "    for i in tqdm(range(1, len(pcd_points)-1)):\n",
    "        \n",
    "        # Perform ICP=]\n",
    "        \n",
    "        sample_next_frame = pcd_points[i]#[np.random.randint(low=0, high=pcd_points[i].shape[0], size=1000),:]\n",
    "        #[np.random.randint(low=0, high=transformed_points.shape[0], size=transformed_points.shape[0]),:]\n",
    "        R,t = icp( transformed_points, sample_next_frame, is_test=True, point_selection=point_selection, no_background_removal = True)\n",
    "        \n",
    "        # Update transformations back to zero frame\n",
    "        #R_to_zero_current = R.dot(R_to_zero_current)\n",
    "        #t_to_zero_current = R.dot(t_to_zero_current) + t\n",
    "        \n",
    "        # Project current PointCloud back to 0-frame space\n",
    "        transformed_points = affine_transform(transformed_points, R, t)\n",
    "        \n",
    "        \n",
    "        transformed_points = np.concatenate((transformed_points, sample_next_frame[np.random.randint(low=0, high=sample_next_frame.shape[0], size=14000),:]))\n",
    "    \n",
    "    # Remove backgrounds in our pcds\n",
    "    # pcd_points = [background_removal(p) for p in pcd_points]\n",
    "    \n",
    "    \n",
    "    # Apply transformation to pcd\n",
    "    # pcd_points_transformed = [affine_transform(pcd_points[i],R_list[i], t_list[i]) \n",
    "                              #for i in range(len(pcd_points)-1)]\n",
    "    \n",
    "    #for i in range(len(pcds)):\n",
    "    #    pcds[i].points = pcd_points_transformed[i]\n",
    "        if i%20==0:\n",
    "            show_fitting_result([transformed_points])\n",
    "    show_fitting_result([transformed_points])\n",
    "    \n",
    "merging_scenes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/99 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 1/99 [00:00<00:25,  3.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 2/99 [00:00<00:22,  4.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 3/99 [00:00<00:22,  4.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 4/99 [00:00<00:22,  4.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 5/99 [00:01<00:24,  3.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 6/99 [00:01<00:25,  3.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 7/99 [00:02<00:27,  3.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 8/99 [00:02<00:28,  3.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  9%|▉         | 9/99 [00:02<00:28,  3.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 10%|█         | 10/99 [00:03<00:27,  3.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 11%|█         | 11/99 [00:03<00:27,  3.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 12/99 [00:03<00:27,  3.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 13%|█▎        | 13/99 [00:03<00:26,  3.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 14%|█▍        | 14/99 [00:04<00:25,  3.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 15%|█▌        | 15/99 [00:04<00:25,  3.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|█▌        | 16/99 [00:04<00:25,  3.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 17/99 [00:05<00:24,  3.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 18%|█▊        | 18/99 [00:05<00:25,  3.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 19%|█▉        | 19/99 [00:05<00:24,  3.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 20/99 [00:06<00:25,  3.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|██        | 21/99 [00:07<00:26,  2.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|██▏       | 22/99 [00:07<00:26,  2.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 23%|██▎       | 23/99 [00:08<00:27,  2.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 24%|██▍       | 24/99 [00:08<00:27,  2.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 25/99 [00:09<00:27,  2.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▋       | 26/99 [00:09<00:27,  2.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|██▋       | 27/99 [00:10<00:27,  2.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|██▊       | 28/99 [00:10<00:27,  2.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|██▉       | 29/99 [00:11<00:26,  2.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███       | 30/99 [00:11<00:26,  2.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 31%|███▏      | 31/99 [00:11<00:26,  2.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 32%|███▏      | 32/99 [00:12<00:26,  2.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 33/99 [00:13<00:26,  2.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 34%|███▍      | 34/99 [00:13<00:26,  2.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 35%|███▌      | 35/99 [00:14<00:26,  2.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▋      | 36/99 [00:14<00:26,  2.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 37%|███▋      | 37/99 [00:15<00:26,  2.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 38/99 [00:16<00:25,  2.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|███▉      | 39/99 [00:16<00:25,  2.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 40/99 [00:17<00:25,  2.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|████▏     | 41/99 [00:17<00:24,  2.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 42%|████▏     | 42/99 [00:17<00:23,  2.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|████▎     | 43/99 [00:17<00:23,  2.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 44%|████▍     | 44/99 [00:18<00:22,  2.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|████▌     | 45/99 [00:18<00:22,  2.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▋     | 46/99 [00:18<00:21,  2.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 47%|████▋     | 47/99 [00:19<00:21,  2.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 48%|████▊     | 48/99 [00:19<00:20,  2.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|████▉     | 49/99 [00:19<00:20,  2.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 51%|█████     | 50/99 [00:20<00:19,  2.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 52%|█████▏    | 51/99 [00:20<00:19,  2.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 53%|█████▎    | 52/99 [00:20<00:18,  2.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████▎    | 53/99 [00:21<00:18,  2.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▍    | 54/99 [00:21<00:17,  2.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████▌    | 55/99 [00:21<00:17,  2.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████▋    | 56/99 [00:22<00:17,  2.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 58%|█████▊    | 57/99 [00:22<00:16,  2.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 59%|█████▊    | 58/99 [00:22<00:16,  2.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 60%|█████▉    | 59/99 [00:22<00:15,  2.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 61%|██████    | 60/99 [00:23<00:15,  2.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████▏   | 61/99 [00:23<00:14,  2.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 63%|██████▎   | 62/99 [00:23<00:14,  2.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 64%|██████▎   | 63/99 [00:24<00:13,  2.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▍   | 64/99 [00:24<00:13,  2.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 66%|██████▌   | 65/99 [00:24<00:13,  2.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 66/99 [00:25<00:12,  2.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 68%|██████▊   | 67/99 [00:25<00:12,  2.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████▊   | 68/99 [00:25<00:11,  2.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████▉   | 69/99 [00:26<00:11,  2.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████   | 70/99 [00:26<00:10,  2.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████▏  | 71/99 [00:26<00:10,  2.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████▎  | 72/99 [00:27<00:10,  2.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▎  | 73/99 [00:27<00:09,  2.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████▍  | 74/99 [00:27<00:09,  2.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 76%|███████▌  | 75/99 [00:28<00:09,  2.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 77%|███████▋  | 76/99 [00:28<00:08,  2.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 78%|███████▊  | 77/99 [00:29<00:08,  2.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 79%|███████▉  | 78/99 [00:29<00:07,  2.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 80%|███████▉  | 79/99 [00:29<00:07,  2.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 81%|████████  | 80/99 [00:30<00:07,  2.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 82%|████████▏ | 81/99 [00:30<00:06,  2.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████▎ | 82/99 [00:30<00:06,  2.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████▍ | 83/99 [00:31<00:05,  2.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████▍ | 84/99 [00:31<00:05,  2.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████▌ | 85/99 [00:31<00:05,  2.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████▋ | 86/99 [00:32<00:04,  2.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 88%|████████▊ | 87/99 [00:32<00:04,  2.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 89%|████████▉ | 88/99 [00:32<00:04,  2.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 90%|████████▉ | 89/99 [00:33<00:03,  2.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 91%|█████████ | 90/99 [00:33<00:03,  2.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 92%|█████████▏| 91/99 [00:33<00:02,  2.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 93%|█████████▎| 92/99 [00:34<00:02,  2.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 94%|█████████▍| 93/99 [00:34<00:02,  2.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████▍| 94/99 [00:35<00:01,  2.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████▌| 95/99 [00:35<00:01,  2.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████▋| 96/99 [00:35<00:01,  2.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████▊| 97/99 [00:35<00:00,  2.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 99%|█████████▉| 98/99 [00:36<00:00,  2.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 99/99 [00:36<00:00,  2.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "#3.2 approach 2\n",
    "\n",
    "def merging_scenes(pcd_points= pcd_points, point_selection='uniform'):\n",
    "    \n",
    "  \n",
    "    \n",
    "    # Tansform all frames back to zero-frame space \n",
    "    R_to_zero_current = np.eye(3)\n",
    "    t_to_zero_current = np.zeros(3)\n",
    "    transformed_points =  pcd_points[0][np.random.randint(low=0, high=pcd_points[0].shape[0], size=1010)]\n",
    "\n",
    "    for i in tqdm(range(1, len(pcd_points))):\n",
    "        \n",
    "        # Perform ICP\n",
    "        R,t = icp(pcd_points[i], transformed_points, is_test=True, point_selection=point_selection)\n",
    "        \n",
    "        # Update transformations back to zero frame\n",
    "        #R_to_zero_current = R.dot(R_to_zero_current)\n",
    "        #t_to_zero_current = R.dot(t_to_zero_current) + t\n",
    "        \n",
    "        # Project current PointCloud back to 0-frame space\n",
    "        sample_transformed = affine_transform(pcd_points[i][np.random.randint(low=0, high=pcd_points[i].shape[0], size=600)], R, t)\n",
    "        transformed_points = np.concatenate((transformed_points,sample_transformed))#[affine_transform(pcd_points[i][np.random.randint(low=0, high=pcd_points[i].shape[0], size=600)] , R_to_zero_current , t_to_zero_current)]\n",
    "    \n",
    "    # Remove backgrounds in our pcds\n",
    "    # pcd_points = [background_removal(p) for p in pcd_points]\n",
    "    \n",
    "    \n",
    "    # Apply transformation to pcd\n",
    "    # pcd_points_transformed = [affine_transform(pcd_points[i],R_list[i], t_list[i]) \n",
    "                              #for i in range(len(pcd_points)-1)]\n",
    "    \n",
    "    #for i in range(len(pcds)):\n",
    "    #    pcds[i].points = pcd_points_transformed[i]\n",
    "        \n",
    "    show_fitting_result([transformed_points])\n",
    "    \n",
    "    \n",
    "merging_scenes()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
